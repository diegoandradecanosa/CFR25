{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de un modelo de difusión\n",
    "\n",
    "*Este tutorial es una adaptación de:* https://huggingface.co/docs/diffusers/tutorials/basic_training\n",
    "\n",
    "La generación de imágenes no condicionadas es un uso popular de los modelos de difusión, que genera imágenes similares a aquellas para las que fue entrenado. Además, los mejores resultados se obtienen después de hacer un fine-tuning de un checkpoint de modelo pre-entrenado con un dataset más específico. Este [enlace](https://huggingface.co/search/full-text?q=unconditional-image-generation&type=model) contiene muchos de estos checkpoints.\n",
    "\n",
    "En este notebook vamos a entrenar el modelo *UNet2DModel* desde cero en un conjunto del dataset [Smithsonian Butterflies](https://huggingface.co/datasets/huggan/smithsonian_butterflies_subset).\n",
    "\n",
    "Antes de empezar tenemos que instalar en nuestro entorno las librerías necesarias para realizar entrenamiento de modelos con diffusers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install diffusers[training]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mydiffusers (venv)",
   "language": "python",
   "name": "mydiffusers"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
