{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoClass\n",
    "\n",
    "*Este tutorial es una adaptación de:* https://huggingface.co/docs/transformers/v4.47.1/es/autoclass_tutorial\n",
    "\n",
    "Es útil tener la posibilidad de cargar un modelo de arquitectura transformers preentrenado desde un *checkpoint* determinado. Los *checkpoints* son puntos  de entrenamiento del modelo para los que se han almacenado todos los elementos que constituyen el estado del modelo, de forma que este estado pueda ser fielmente replicado.\n",
    "\n",
    "Por ejemplo, para la arquitectura de modelo Bert, existen varios checkpoints como por ejemplo: bert-base-uncased, bert-base-cased, bert-base-multlingual-case, etc... Cada uno de estos checkpoints contiene los valores de los parámetros del modelo entrenados para operar con ciertos condicionantes o restricciones utilizando el modelo Bert. Por ejemplo, la diferencia entre las versiones cased and uncased es si hacen distinción o no entre mayúsculas y minúsculas. Las versiones etiquetadas como multilingual hacen referencia a la capacidad del modelo para operar en diferentes idiomas. Normalmente los modelos están entrenados para un idioma base, que suele ser el inglés para el mundo occidental, pero en China el idioma base suele ser el chino."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La familia de las *AutoClass* son un bloque constructor básico de la librería Transformer. Permiten la utilización de Modelos y de distintos componentes de los mismos, sin tener que elegir la clase adecuada para el checkpoint que se está utilizando. La AutoClass correspondiente se encargará de cargar el componente adecuado para la arquitectura del modelo cargado.\n",
    "\n",
    "Existen *AutoClass* tanto para modelos como para distintos componentes de los mismos:\n",
    "\n",
    "- Tokenizer: AutoTokenizer\n",
    "- ImageProcessor: AutoImageProcessor\n",
    "- Backbone (Embedding): AutoBackbone\n",
    "- Feature Extractor: AutoFeatureExtractor\n",
    "- Processor: AutoProcessor\n",
    "- Modelo: AutoModel\n",
    "\n",
    "Veamos ahora ejemplos de varios de estos componentes, empezando por el **AutoTokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0ca905987494aedb0f9096e02f3bdf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b8ba12f29c94aea827705c4d6f560c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "165c8d7d0edf4e128d08efc10cbd7359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4e2a10192d54e1285595b34d9656c70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 1999, 1037, 4920, 1999, 1996, 2598, 2045, 2973, 1037, 7570, 10322, 4183, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "sequence = \"In a hole in the ground there lived a hobbit.\"\n",
    "print(tokenizer(sequence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tareas de procesamiento de imágenes\n",
    "\n",
    "Los *tokenizers* son útiles para tareas de lenguaje, en el caso de modelos cuya entrada es una imagen, se necesita un *Image Processor* que transforme la imagen al formato correcto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3341d15708045d9973981b65c14dd34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)rocessor_config.json:   0%|          | 0.00/255 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor, AutoBackbone\n",
    "import torch\n",
    "from PIL import Image\n",
    "import requests\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "processor = AutoImageProcessor.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siguiendo el flujo de procesamiento de una imagen de entrada, la clase *AutoBackbone* permite utilizar modelos como backbones para extaer los mapas de características de diferentes etapas (o capas) del backbone. En este caso, además de cargar un checkpoint determinado utilizando la función *from_pretrained* puedes indicar como parámetro las capas de las que quieres obtener el mapa de características usando una de estas dos formas:\n",
    "- **out_indices**: es el índice de las capas de las que querrías obtener el mapa de características\n",
    "- **out_features**: es el nombre de las capas de las que querrías obtener el mapa de características\n",
    "\n",
    "Veamos un ejemplo, siguiendo el código anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/swin-tiny-patch4-window7-224 were not used when initializing SwinBackbone: ['classifier.bias', 'classifier.weight', 'swin.layernorm.bias', 'swin.layernorm.weight']\n",
      "- This IS expected if you are initializing SwinBackbone from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing SwinBackbone from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of SwinBackbone were not initialized from the model checkpoint at microsoft/swin-tiny-patch4-window7-224 and are newly initialized: ['swin.hidden_states_norms.stage1.weight', 'swin.hidden_states_norms.stage1.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 96, 56, 56]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoBackbone.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\", out_indices=(1,))\n",
    "inputs = processor(image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "feature_maps = outputs.feature_maps\n",
    "list(feature_maps[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tareas de procesamiento de audio\n",
    "\n",
    "Para tareas de procesamiento de audio podemos usar la clase AutoFeatureExractor para procesar la señal de audio al formato de entrada adecuado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea4b28ea94e640e69e2032af41ede304",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)rocessor_config.json:   0%|          | 0.00/214 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoFeatureExtractor\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\n",
    "    \"ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tareas multimodales\n",
    "\n",
    "Las tareas multimodales requieren un procesado que combine dos tipo de herramientas de preprocesado. Por ejemplo, el modelo LayoutLMV2 necesita un procesador de imágenes para manejar imágenes y un tokenizer para manejar texto. Usando un AutoProcessor podemos generar un preprocesador que combine ambas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d16107bb81e246faaf7e1d586bd76e79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)rocessor_config.json:   0%|          | 0.00/135 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20e703a3b84047d8aab0b32bbb17e499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/707 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b64dfa4d7e114e2c95e88521ef374178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoProcessor\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"microsoft/layoutlmv2-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos\n",
    "\n",
    "La familia de clases AutoModelFor permite la carga de un modelo preentrenado para una tare determinada. En [este enlace](https://huggingface.co/docs/transformers/model_doc/auto#generic-pretraining-classes) podemos encontrar la lista completa. Veamos un ejemplo con la clase *AutoModelForSequenceClassification*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec787e087bb54df393b987c3c8c47c77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10b8de8a0df84df9a713283b72fcab6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert/distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-uncased\", torch_dtype=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos usar el mismo checkpoint para cargar un modelo para una tarea diferente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert/distilbert-base-uncased were not used when initializing DistilBertForTokenClassification: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"distilbert/distilbert-base-uncased\", torch_dtype=\"auto\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytx",
   "language": "python",
   "name": "mytx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
